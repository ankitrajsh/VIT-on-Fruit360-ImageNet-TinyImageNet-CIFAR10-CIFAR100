{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQz_RPW3FRBZ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ie7QGHgAFRBa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ-xKRIGFRBc"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzYEiHy3FRBd",
        "outputId": "cc9d4006-eff2-4c1c-8923-7f4f853db3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2GEAOmLFRBe"
      },
      "source": [
        "## Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JwDDJ2l9FRBf"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 10  # For real training, use num_epochs=100. 10 is a test value\n",
        "image_size = 72  # We'll resize input images to this size\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [\n",
        "    2048,\n",
        "    1024,\n",
        "]  # Size of the dense layers of the final classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKVpNwiAFRBh"
      },
      "source": [
        "## Use data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UCHmgpAFFRBh"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coZ2y9n4FRBi"
      },
      "source": [
        "## Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9XKcuyJcFRBj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=keras.activations.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHK3da40FRBk"
      },
      "source": [
        "## Implement patch creation as a layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7ahq4FUpFRBk"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        input_shape = ops.shape(images)\n",
        "        batch_size = input_shape[0]\n",
        "        height = input_shape[1]\n",
        "        width = input_shape[2]\n",
        "        channels = input_shape[3]\n",
        "        num_patches_h = height // self.patch_size\n",
        "        num_patches_w = width // self.patch_size\n",
        "        patches = keras.ops.image.extract_patches(images, size=self.patch_size)\n",
        "        patches = ops.reshape(\n",
        "            patches,\n",
        "            (\n",
        "                batch_size,\n",
        "                num_patches_h * num_patches_w,\n",
        "                self.patch_size * self.patch_size * channels,\n",
        "            ),\n",
        "        )\n",
        "        return patches\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"patch_size\": self.patch_size})\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQSAT2o9FRBl"
      },
      "source": [
        "Let's display patches for a sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "mMfIP3fjFRBl",
        "outputId": "2f32d5ce-6c63-4e8f-da3a-726a05c7d1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = ops.image.resize(\n",
        "    ops.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = ops.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(ops.convert_to_numpy(patch_img).astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnIpidkxFRBm"
      },
      "source": [
        "## Implement the patch encoding layer\n",
        "\n",
        "The `PatchEncoder` layer will linearly transform a patch by projecting it into a\n",
        "vector of size `projection_dim`. In addition, it adds a learnable position\n",
        "embedding to the projected vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0avCC-nTFRBm"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = ops.expand_dims(\n",
        "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
        "        )\n",
        "        projected_patches = self.projection(patch)\n",
        "        encoded = projected_patches + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"num_patches\": self.num_patches})\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNM3bcOwFRBn"
      },
      "source": [
        "## Build the ViT model\n",
        "\n",
        "The ViT model consists of multiple Transformer blocks,\n",
        "which use the `layers.MultiHeadAttention` layer as a self-attention mechanism\n",
        "applied to the sequence of patches. The Transformer blocks produce a\n",
        "`[batch_size, num_patches, projection_dim]` tensor, which is processed via an\n",
        "classifier head with softmax to produce the final class probabilities output.\n",
        "\n",
        "Unlike the technique described in the [paper](https://arxiv.org/abs/2010.11929),\n",
        "which prepends a learnable embedding to the sequence of encoded patches to serve\n",
        "as the image representation, all the outputs of the final Transformer block are\n",
        "reshaped with `layers.Flatten()` and used as the image\n",
        "representation input to the classifier head.\n",
        "Note that the `layers.GlobalAveragePooling1D` layer\n",
        "could also be used instead to aggregate the outputs of the Transformer block,\n",
        "especially when the number of patches and the projection dimensions are large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lbeagLUaFRBn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_vit_classifier():\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCSE0VxjFRBo"
      },
      "source": [
        "## Compile, train, and evaluate the mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gee_8uqHFRBo",
        "outputId": "2f349a71-1d08-4cbe-dfc4-84f0bd61a4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 2s/step - accuracy: 0.0284 - loss: 4.8943 - top-5-accuracy: 0.1097 - val_accuracy: 0.0940 - val_loss: 3.9606 - val_top-5-accuracy: 0.2966\n",
            "Epoch 2/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 2s/step - accuracy: 0.0871 - loss: 4.0146 - top-5-accuracy: 0.2715 - val_accuracy: 0.1580 - val_loss: 3.5965 - val_top-5-accuracy: 0.3998\n",
            "Epoch 3/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 2s/step - accuracy: 0.1253 - loss: 3.7313 - top-5-accuracy: 0.3554 - val_accuracy: 0.1880 - val_loss: 3.4182 - val_top-5-accuracy: 0.4608\n",
            "Epoch 4/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 2s/step - accuracy: 0.1578 - loss: 3.5301 - top-5-accuracy: 0.4151 - val_accuracy: 0.2254 - val_loss: 3.1983 - val_top-5-accuracy: 0.5072\n",
            "Epoch 5/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 2s/step - accuracy: 0.1847 - loss: 3.3652 - top-5-accuracy: 0.4635 - val_accuracy: 0.2462 - val_loss: 3.0843 - val_top-5-accuracy: 0.5326\n",
            "Epoch 6/10\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 2s/step - accuracy: 0.2117 - loss: 3.2495 - top-5-accuracy: 0.4938 - val_accuracy: 0.2604 - val_loss: 2.9723 - val_top-5-accuracy: 0.5650\n",
            "Epoch 7/10\n",
            "\u001b[1m162/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.2259 - loss: 3.1079 - top-5-accuracy: 0.5296"
          ]
        }
      ],
      "source": [
        "\n",
        "def run_experiment(model):\n",
        "    optimizer = keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)\n",
        "\n",
        "\n",
        "def plot_history(item):\n",
        "    plt.plot(history.history[item], label=item)\n",
        "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(item)\n",
        "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history(\"loss\")\n",
        "plot_history(\"top-5-accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-wefkBnFRBp"
      },
      "source": [
        "After 100 epochs, the ViT model achieves around 55% accuracy and\n",
        "82% top-5 accuracy on the test data. These are not competitive results on the CIFAR-100 dataset,\n",
        "as a ResNet50V2 trained from scratch on the same data can achieve 67% accuracy.\n",
        "\n",
        "Note that the state of the art results reported in the\n",
        "[paper](https://arxiv.org/abs/2010.11929) are achieved by pre-training the ViT model using\n",
        "the JFT-300M dataset, then fine-tuning it on the target dataset. To improve the model quality\n",
        "without pre-training, you can try to train the model for more epochs, use a larger number of\n",
        "Transformer layers, resize the input images, change the patch size, or increase the projection dimensions.\n",
        "Besides, as mentioned in the paper, the quality of the model is affected not only by architecture choices,\n",
        "but also by parameters such as the learning rate schedule, optimizer, weight decay, etc.\n",
        "In practice, it's recommended to fine-tune a ViT model\n",
        "that was pre-trained using a large, high-resolution dataset."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification_with_vision_transformer",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}